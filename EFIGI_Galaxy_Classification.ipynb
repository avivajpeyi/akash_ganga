{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EFIGI_Galaxy_Classification.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [
        "IbUR2n9suuLJ",
        "-LqW2qQLUjnO",
        "2pfKo3b02shb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lPEdA0Hb4vOf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Galaxy Calssification using  the EFIGI reference dataset \n",
        "\n",
        "## Author: Avi Vajpeyi, Dr. Rahul Remanan \n",
        "### 2018 Summer Internship, [Moad Computer](https://www.moad.computer)\n",
        "\n",
        "### [EFIGI data](https://www.astromatic.net/projects/efigi)\n"
      ]
    },
    {
      "metadata": {
        "id": "Xr-oj4HKEwpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Copy preprocessed data to Drive\n"
      ]
    },
    {
      "metadata": {
        "id": "7n3jY0kGFJNd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copy data from https://goo.gl/rqMD9B to your home dir in Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "wJ6dPot4HRTa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# FALSE to use the processed data saved in https://goo.gl/rqMD9B   \n",
        "# TRUE to download and reprocess data from EFIGI website\n",
        "download_raw_data = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8zio0_ian14",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Connect Google Drive to this session"
      ]
    },
    {
      "metadata": {
        "id": "2Zzh0e9qjDCJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code adds ./drive/ (your google drive home folder) to the current session. You cannot cd into this but can access the files on google drive this way.\n",
        "\n",
        "Code obtained from [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)"
      ]
    },
    {
      "metadata": {
        "id": "O2uIr4PHhl2U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2629
        },
        "outputId": "bcaf38a6-2ddc-40c5-cf4f-8b9617c98954",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531333222660,
          "user_tz": 240,
          "elapsed": 477158,
          "user": {
            "displayName": "Moad Computer",
            "photoUrl": "//lh5.googleusercontent.com/-Ic6_gWlgQXo/AAAAAAAAAAI/AAAAAAAAABA/KunqdqgBsx4/s50-c-k-no/photo.jpg",
            "userId": "105137350204760020224"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "!mkdir -p drive/EFIGI_Galaxy_Classification/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18396 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Preparing to unpack .../04-gnupg_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Preparing to unpack .../05-gnupg-agent_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg-agent (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../06-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../07-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../08-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../09-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../10-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../11-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../12-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../13-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../14-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../15-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../16-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../17-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../18-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../19-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../20-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../21-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../22-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../23-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../24-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../25-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up gnupg-agent (2.1.15-1ubuntu8.1) ...\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up gnupg (2.1.15-1ubuntu8.1) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp1wja2r82/pubring.gpg' created\n",
            "gpg: /tmp/tmp1wja2r82/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19804 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "mkdir: cannot create directory ‘drive/EFIGI_Galaxy_Classification/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nh9-Pk3T0tnO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Copy and unzip sorted data from drive to local"
      ]
    },
    {
      "metadata": {
        "id": "PILw4g1D2Lkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data accessible from ./data/train and ./data/validation"
      ]
    },
    {
      "metadata": {
        "id": "bp4EJ2vj1D1Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! cp ./drive/EFIGI_Galaxy_Classification/data/sorted_data.zip .\n",
        "! unzip - q sorted_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbUR2n9suuLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define python function to run linux commands"
      ]
    },
    {
      "metadata": {
        "id": "jOBuQwIbvEE3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        " \n",
        "def execute_in_shell(command=None, \n",
        "                     verbose = False):\n",
        "    \"\"\" \n",
        "        command -- keyword argument, takes a list as input\n",
        "        verbsoe -- keyword argument, takes a boolean value as input\n",
        "    \n",
        "        This is a function that executes shell scripts from within python.\n",
        "        \n",
        "        Keyword argument 'command', should be a list of shell commands.\n",
        "        Keyword argument 'versboe', should be a boolean value to set verbose level.\n",
        "        \n",
        "        Example usage: execute_in_shell(command = ['ls ./some/folder/',\n",
        "                                                    ls ./some/folder/  -1 | wc -l'],\n",
        "                                        verbose = True ) \n",
        "                                        \n",
        "        This command returns dictionary with elements: Output and Error.\n",
        "        \n",
        "        Output records the console output,\n",
        "        Error records the console error messages.\n",
        "                                        \n",
        "    \"\"\"\n",
        "    error = []\n",
        "    output = []\n",
        "    \n",
        "    if isinstance(command, list):\n",
        "        for i in range(len(command)):\n",
        "            try:\n",
        "                process = subprocess.Popen(command[i], shell=True, stdout=subprocess.PIPE)\n",
        "                process.wait()\n",
        "                out, err = process.communicate()\n",
        "                error.append(err)\n",
        "                output.append(out)\n",
        "                if verbose:\n",
        "                    print ('Success running shell command: {}'.format(command[i]))\n",
        "            except Exception as e:\n",
        "                print ('Failed running shell command: {}'.format(command[i]))\n",
        "                if verbose:\n",
        "                    print(type(e))\n",
        "                    print(e.args)\n",
        "                    print(e)\n",
        "                \n",
        "    else:\n",
        "        print ('The argument command takes a list input ...')\n",
        "    return {'Output': output, 'Error': error }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cq8A4j1B5S59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download and sort data\n",
        "Currently only using coloured processed images rather than the sperate images that the final image is composed of. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D-cu1tAhVhQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data\n",
        "The EFIGI dataset info we are using is in 6 separate compressed archives (gzipped\n",
        "tar format):\n",
        "- efigi_tables-1.6.tgz: 6 ASCII tables, including morphological information\n",
        "- efigi_png_gri-1.6.tgz: 4458 PNG images in the SDSS g,r and i bands\n",
        "- efigi_ima_u-1.6.tgz: 4458 galaxy images in the SDSS u-band (FITS format)\n",
        "- efigi_ima_g-1.6.tgz: 4458 galaxy images in the SDSS g-band (FITS format)\n",
        "- efigi_ima_r-1.6.tgz: 4458 galaxy images in the SDSS r-band (FITS format)\n",
        "- efigi_ima_i-1.6.tgz: 4458 galaxy images in the SDSS i-band (FITS format)\n",
        "- efigi_ima_z-1.6.tgz: 4458 galaxy images in the SDSS z-band (FITS format)\n"
      ]
    },
    {
      "metadata": {
        "id": "J2Q_47OX5aeC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  ! mkdir ./data\n",
        "  ! mkdir ./data/raw\n",
        "\n",
        "  ! wget  -O ./data/raw/efigi-1.6.tgz \"https://www.astromatic.net/download/efigi/efigi_tables-1.6.2.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_png_gri-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_u_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_u-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_g_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_g-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_r_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_r-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_i_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_i-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_z_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_z-1.6.tgz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ncwhv7gGx-7P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Zip and move raw files to drive\n",
        "DO ONLY ONCE"
      ]
    },
    {
      "metadata": {
        "id": "NgdwwES6xwIE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " if download_raw_data:\n",
        "  ! zip -r raw_data.zip data/raw\n",
        "  ! mv -v raw_data.zip drive/EFIGI_Galaxy_Classification/data/raw/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9qyTgep-nXS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Unpack data from tgz\n",
        "Data stored in\n",
        "\n",
        "* Tables:  ` ./data/raw/efigi-1.6/ `\n",
        "* Colored Images:   ` ./data/raw/efigi-1.6/png ` \n",
        "* FITS: `/efigi-1.6/ima_g,  ima_i, ima_u, ima_z`\n"
      ]
    },
    {
      "metadata": {
        "id": "CDtOzw_Lv-Wp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  import glob\n",
        "  tgz_files = glob.glob(\"./data/raw/*tgz\")\n",
        "  for tgz_file in tgz_files:\n",
        "    command=[\"tar xzf \"+tgz_file+\" -C ./data/raw/\", \"rm \"+tgz_file]\n",
        "    execute_in_shell(command, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LqW2qQLUjnO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert fits to png"
      ]
    },
    {
      "metadata": {
        "id": "7Z5Hha_mS3_v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  ! pip install astropy --no-deps\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.pyplot as plt\n",
        "  from astropy.utils.data import get_pkg_data_filename\n",
        "  from astropy.io import fits\n",
        "  import numpy as np\n",
        "  import glob\n",
        "  import os\n",
        "  import cv2\n",
        "\n",
        "  def fits_to_png(fits_fn):\n",
        "      # Generally the image information is located in the Primary HDU (ext 0)\n",
        "      # read the image data from this first extension using the keyword argument\n",
        "      data = fits.getdata(fits_fn, ext=0)\n",
        "\n",
        "      sizes = np.shape(data)\n",
        "      height = float(sizes[0])\n",
        "      width = float(sizes[1])\n",
        "\n",
        "      fig = plt.figure()\n",
        "      fig.set_size_inches(width / height, 1, forward=False)\n",
        "      ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "      ax.set_axis_off()\n",
        "      fig.add_axes(ax)\n",
        "\n",
        "      ax.imshow(data, cmap=\"binary\")\n",
        "\n",
        "      # createing png filename from fits filename\n",
        "      png_fn = fits_fn.split(\".fits\")[0] + \".png\"\n",
        "\n",
        "\n",
        "      plt.savefig(png_fn, dpi=height)\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "  def fits_folder_to_png(dir, verbose):\n",
        "\n",
        "      fits_files = glob.glob( dir+\"*.fits\")\n",
        "      num_files = len(fits_files)\n",
        "      status_flag = num_files * 0.1\n",
        "\n",
        "      for i in range(0, num_files):\n",
        "          fits_to_png(fits_files[i])\n",
        "\n",
        "          if verbose and i > status_flag:\n",
        "              status_flag += num_files * 0.1\n",
        "              p_done = i / num_files * 100\n",
        "              print(str(p_done)+\"% processed\")\n",
        "\n",
        "  def delete_fits_from_folder(dir):\n",
        "      fits_files = glob.glob(dir+\"*.fits\")\n",
        "      for f in fits_files:\n",
        "        os.remove(f)\n",
        "\n",
        "\n",
        "  def make_movie_from_png(video_name, dir):\n",
        "\n",
        "      images = glob.glob(dir + \"*.png\")\n",
        "      frame = cv2.imread(images[0])\n",
        "      height, width, layers = frame.shape\n",
        "\n",
        "      video = cv2.VideoWriter(video_name, -1, 25, (width, height))\n",
        "\n",
        "      for image in images:\n",
        "          video.write(cv2.imread(image))\n",
        "\n",
        "      cv2.destroyAllWindows()\n",
        "      video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lJPw7JiOp8IT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1511
        },
        "outputId": "aeeb5f79-3a43-4772-ad1a-cc01aa5f5e7d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531334650334,
          "user_tz": 240,
          "elapsed": 2752,
          "user": {
            "displayName": "Moad Computer",
            "photoUrl": "//lh5.googleusercontent.com/-Ic6_gWlgQXo/AAAAAAAAAAI/AAAAAAAAABA/KunqdqgBsx4/s50-c-k-no/photo.jpg",
            "userId": "105137350204760020224"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/DWARF"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PGC0009283_g.png  PGC0039965_g.png  PGC0041494_g.png  PGC0042638.png\r\n",
            "PGC0009283_i.png  PGC0039965_i.png  PGC0041494_i.png  PGC0042638_z.png\r\n",
            "PGC0009283_r.png  PGC0039965.png    PGC0041494.png    PGC0042744_g.png\r\n",
            "PGC0009283_u.png  PGC0039965_r.png  PGC0041494_r.png  PGC0042744.png\r\n",
            "PGC0009283_z.png  PGC0039965_u.png  PGC0041494_u.png  PGC0042744_u.png\r\n",
            "PGC0010132_g.png  PGC0040002_g.png  PGC0041505_g.png  PGC0042744_z.png\r\n",
            "PGC0010132_i.png  PGC0040002_i.png  PGC0041505_i.png  PGC0042769_g.png\r\n",
            "PGC0010132.png\t  PGC0040002_r.png  PGC0041505_r.png  PGC0042769.png\r\n",
            "PGC0010132_r.png  PGC0040002_z.png  PGC0041505_u.png  PGC0042769_r.png\r\n",
            "PGC0010132_z.png  PGC0040032_g.png  PGC0041505_z.png  PGC0042769_u.png\r\n",
            "PGC0025858_g.png  PGC0040032_i.png  PGC0041546_g.png  PGC0042769_z.png\r\n",
            "PGC0025858_i.png  PGC0040032.png    PGC0041546_i.png  PGC0042949_g.png\r\n",
            "PGC0025858.png\t  PGC0040032_r.png  PGC0041546_r.png  PGC0042949_i.png\r\n",
            "PGC0025858_u.png  PGC0040032_z.png  PGC0041546_u.png  PGC0042949.png\r\n",
            "PGC0025858_z.png  PGC0040068_g.png  PGC0041546_z.png  PGC0042949_z.png\r\n",
            "PGC0029488_g.png  PGC0040068.png    PGC0041552_g.png  PGC0042969_g.png\r\n",
            "PGC0029488_i.png  PGC0040068_r.png  PGC0041552_i.png  PGC0042969.png\r\n",
            "PGC0029488_u.png  PGC0040068_u.png  PGC0041552.png    PGC0042969_r.png\r\n",
            "PGC0029488_z.png  PGC0040171_g.png  PGC0041552_u.png  PGC0042969_z.png\r\n",
            "PGC0032471_g.png  PGC0040171_i.png  PGC0041552_z.png  PGC0043100_g.png\r\n",
            "PGC0032471.png\t  PGC0040171.png    PGC0041586_g.png  PGC0043100_i.png\r\n",
            "PGC0032471_r.png  PGC0040171_r.png  PGC0041586_i.png  PGC0043100_r.png\r\n",
            "PGC0032471_u.png  PGC0040171_u.png  PGC0041586.png    PGC0043100_z.png\r\n",
            "PGC0032471_z.png  PGC0040171_z.png  PGC0041586_r.png  PGC0043386_i.png\r\n",
            "PGC0034934_i.png  PGC0040209_g.png  PGC0041586_u.png  PGC0043386.png\r\n",
            "PGC0034934.png\t  PGC0040209_i.png  PGC0041586_z.png  PGC0043386_r.png\r\n",
            "PGC0034934_r.png  PGC0040209.png    PGC0041606_g.png  PGC0043386_u.png\r\n",
            "PGC0034934_u.png  PGC0040209_r.png  PGC0041606_i.png  PGC0043386_z.png\r\n",
            "PGC0034934_z.png  PGC0040209_u.png  PGC0041606.png    PGC0044414_g.png\r\n",
            "PGC0034969_g.png  PGC0040209_z.png  PGC0041606_r.png  PGC0044414_i.png\r\n",
            "PGC0034969_i.png  PGC0040485_g.png  PGC0041606_u.png  PGC0044414_r.png\r\n",
            "PGC0034969.png\t  PGC0040485_r.png  PGC0041606_z.png  PGC0044414_u.png\r\n",
            "PGC0034969_r.png  PGC0040485_u.png  PGC0041614_g.png  PGC0044414_z.png\r\n",
            "PGC0034969_u.png  PGC0040727_g.png  PGC0041614_i.png  PGC0044782_g.png\r\n",
            "PGC0034969_z.png  PGC0040727_i.png  PGC0041614.png    PGC0044782_i.png\r\n",
            "PGC0035852_g.png  PGC0040727.png    PGC0041614_r.png  PGC0044782.png\r\n",
            "PGC0035852_i.png  PGC0040727_r.png  PGC0041828.png    PGC0044782_u.png\r\n",
            "PGC0035852.png\t  PGC0040727_z.png  PGC0041828_r.png  PGC0044782_z.png\r\n",
            "PGC0035852_r.png  PGC0040852_g.png  PGC0041828_z.png  PGC0045897_g.png\r\n",
            "PGC0035852_u.png  PGC0040852.png    PGC0042223_g.png  PGC0045897_i.png\r\n",
            "PGC0035852_z.png  PGC0040852_r.png  PGC0042223.png    PGC0045897.png\r\n",
            "PGC0036750_g.png  PGC0040852_z.png  PGC0042223_r.png  PGC0045897_r.png\r\n",
            "PGC0036750_i.png  PGC0040903_g.png  PGC0042223_z.png  PGC0045897_u.png\r\n",
            "PGC0036750.png\t  PGC0040903_i.png  PGC0042253_g.png  PGC0045897_z.png\r\n",
            "PGC0036750_r.png  PGC0040903.png    PGC0042253.png    PGC0048811_g.png\r\n",
            "PGC0036750_u.png  PGC0040903_r.png  PGC0042253_r.png  PGC0048811_i.png\r\n",
            "PGC0036750_z.png  PGC0040903_z.png  PGC0042253_u.png  PGC0048811.png\r\n",
            "PGC0038624_g.png  PGC0040964_g.png  PGC0042253_z.png  PGC0048811_r.png\r\n",
            "PGC0038624_i.png  PGC0040964.png    PGC0042427_g.png  PGC0048811_u.png\r\n",
            "PGC0038624.png\t  PGC0040964_u.png  PGC0042427_i.png  PGC0048811_z.png\r\n",
            "PGC0038624_u.png  PGC0040964_z.png  PGC0042427.png    PGC0049343_g.png\r\n",
            "PGC0038624_z.png  PGC0040985_g.png  PGC0042427_r.png  PGC0049343_i.png\r\n",
            "PGC0038684_g.png  PGC0040985_i.png  PGC0042427_z.png  PGC0049343.png\r\n",
            "PGC0038684_i.png  PGC0040985.png    PGC0042430_i.png  PGC0049343_r.png\r\n",
            "PGC0038684.png\t  PGC0040985_r.png  PGC0042430.png    PGC0049343_u.png\r\n",
            "PGC0038684_u.png  PGC0040985_z.png  PGC0042430_r.png  PGC0049343_z.png\r\n",
            "PGC0038684_z.png  PGC0041054_g.png  PGC0042430_u.png  PGC0049353.png\r\n",
            "PGC0039215_g.png  PGC0041054.png    PGC0042447_g.png  PGC0049353_r.png\r\n",
            "PGC0039215_i.png  PGC0041054_u.png  PGC0042447_i.png  PGC0049353_u.png\r\n",
            "PGC0039215.png\t  PGC0041155_i.png  PGC0042447.png    PGC0049353_z.png\r\n",
            "PGC0039215_r.png  PGC0041155.png    PGC0042447_r.png  PGC0049571_g.png\r\n",
            "PGC0039215_u.png  PGC0041155_r.png  PGC0042447_u.png  PGC0049571_i.png\r\n",
            "PGC0039215_z.png  PGC0041155_u.png  PGC0042447_z.png  PGC0049571.png\r\n",
            "PGC0039256_g.png  PGC0041155_z.png  PGC0042503_g.png  PGC0049571_u.png\r\n",
            "PGC0039256_i.png  PGC0041272_g.png  PGC0042503_i.png  PGC0049704_g.png\r\n",
            "PGC0039256.png\t  PGC0041272.png    PGC0042503.png    PGC0049704.png\r\n",
            "PGC0039256_r.png  PGC0041272_r.png  PGC0042503_r.png  PGC0049704_r.png\r\n",
            "PGC0039256_u.png  PGC0041272_u.png  PGC0042503_u.png  PGC0049704_z.png\r\n",
            "PGC0039256_z.png  PGC0041272_z.png  PGC0042503_z.png  PGC0050144_g.png\r\n",
            "PGC0039397_g.png  PGC0041376_g.png  PGC0042598_g.png  PGC0050144_i.png\r\n",
            "PGC0039397_i.png  PGC0041376_i.png  PGC0042598.png    PGC0050144_r.png\r\n",
            "PGC0039397.png\t  PGC0041376_z.png  PGC0042598_r.png  PGC0050144_u.png\r\n",
            "PGC0039397_r.png  PGC0041435_g.png  PGC0042608_g.png  PGC0050144_z.png\r\n",
            "PGC0039397_u.png  PGC0041435_i.png  PGC0042608.png    PGC0050338_g.png\r\n",
            "PGC0039503_r.png  PGC0041435.png    PGC0042608_r.png  PGC0050338_i.png\r\n",
            "PGC0039503_u.png  PGC0041435_r.png  PGC0042608_u.png  PGC0050338.png\r\n",
            "PGC0039503_z.png  PGC0041435_u.png  PGC0042608_z.png  PGC0050338_r.png\r\n",
            "PGC0039708_g.png  PGC0041435_z.png  PGC0042620_g.png  PGC0050338_z.png\r\n",
            "PGC0039708_i.png  PGC0041457_g.png  PGC0042620.png    PGC0053949_g.png\r\n",
            "PGC0039708.png\t  PGC0041457_i.png  PGC0042620_r.png  PGC0053949_i.png\r\n",
            "PGC0039708_r.png  PGC0041457.png    PGC0042620_u.png  PGC0053949.png\r\n",
            "PGC0039708_u.png  PGC0041457_u.png  PGC0042638_g.png  PGC0053949_r.png\r\n",
            "PGC0039708_z.png  PGC0041457_z.png  PGC0042638_i.png  PGC0053949_z.png\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vLkULVfzMzna",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This can take a while...Can be timed out and if you are then run again, itll pick up where it left off."
      ]
    },
    {
      "metadata": {
        "id": "oK3zMZlc0JmL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "FITS_folders = [\"ima_g\", \"ima_i\",\"ima_u\",\"ima_z\",\"ima_r\"]\n",
        "for fits_folder in FITS_folders:\n",
        "  dir = \"./data/raw/efigi-1.6/\"+fits_folder+\"/\"\n",
        "  print(\"Processing \"+dir)\n",
        "  fits_folder_to_png(dir, verbose=True)\n",
        "  delete_fits_from_folder(dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRDdIwgRMrjG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Galaxy Type Enum "
      ]
    },
    {
      "metadata": {
        "id": "5u3oX1sOMqyV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  from enum import Enum, auto, unique\n",
        "  @unique\n",
        "  class T(Enum):\n",
        "    ''' Enum to store the different types of galaxies\n",
        "    '''\n",
        "    ELLIPTICAL = auto()\n",
        "    LENTICULAR = auto()\n",
        "    SPIRAL = auto()\n",
        "    IRREGULAR = auto()\n",
        "    DWARF = auto()\n",
        "\n",
        "    def __str__(self):\n",
        "      '''To print the name of the galaxy type when enum printed\n",
        "      '''\n",
        "      return str(self.name)\n",
        "\n",
        "  def check_class(t_val):\n",
        "    '''Takes the t_val attribute and returns the associated enum\n",
        "    '''\n",
        "    try:\n",
        "      t_val = int(t_val)\n",
        "    except ValueError:\n",
        "      pass  # it was a string, not an int.\n",
        "    if t_val < -3:\n",
        "      return T.ELLIPTICAL\n",
        "    elif  t_val < 0:\n",
        "      return T.LENTICULAR\n",
        "    elif t_val < 10:\n",
        "      return T.SPIRAL\n",
        "    elif t_val == 10:\n",
        "      return T.IRREGULAR\n",
        "    elif t_val == 11:\n",
        "      return T.DWARF\n",
        "    else:\n",
        "      print (\"ERROR\")\n",
        "      # raise exception\n",
        "      return null     \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvCeZeuWG61a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Organisational Folders"
      ]
    },
    {
      "metadata": {
        "id": "M3DXbGaCG6Eg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  galaxy_classes = [name for name, gal_type in T.__members__.items()]\n",
        "  execute_in_shell([\"mkdir ./data/train ./data/validation\"])\n",
        "  for galaxy_class in galaxy_classes:\n",
        "    commands =[\"mkdir ./data/train/{} ./data/validation/{}\"\n",
        "               .format(galaxy_class,galaxy_class)]\n",
        "    execute_in_shell(commands)\n",
        "\n",
        "  print(\"Folders in ./data/train/:\")\n",
        "  !ls ./data/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w54wmJq1B9b4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Move files from orignal folder to their classes folder\n",
        "\n",
        "The table `data/raw/efigi-1.6/EFIGI_attributes.txt` has several attributes. We need the \"PGC_name\" and \"T\" (the file name and EFIGI morphological type). Based on this, we will move the file from `./raw` to `./train/{type}`"
      ]
    },
    {
      "metadata": {
        "id": "FsTTBmN9DtjF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  import shutil\n",
        "\n",
        "\n",
        "  def row_generator(filepath):\n",
        "    ''' Grabs one row of the txt file if its not a comment\n",
        "    '''\n",
        "    with open(filepath) as fp:\n",
        "\n",
        "        # Skip initial comments that starts with #\n",
        "        while True:\n",
        "            row = fp.readline()\n",
        "            if not row.startswith('#'):\n",
        "                break\n",
        "\n",
        "        # Second while loop to process the rest of the file\n",
        "        while row:\n",
        "            yield (row)\n",
        "            row = fp.readline()\n",
        "\n",
        "\n",
        "\n",
        "  def move_file_by_class(filename, type, image_foldername):\n",
        "    current_dir = \"data/raw/efigi-1.6/\"+image_foldername+\"/\"+filename\n",
        "    destination_dir = \"data/train/\"+ type.name + \"/\" + filename\n",
        "    shutil.move(current_dir, destination_dir)\n",
        "\n",
        "\n",
        "  def move_files_according_to_txt(txt_filepath, img_folder, extension, verbose):\n",
        "    print(\"Moving files from \"+img_folder)\n",
        "\n",
        "    count = 0\n",
        "    for line in row_generator(txt_filepath):\n",
        "      attributes = line.split()\n",
        "\n",
        "      # create file name based on PGC_name\n",
        "      if extension is None:\n",
        "        image_file_name = attributes[0]+\".png\"\n",
        "      else:\n",
        "        image_file_name = attributes[0]+\"_\"+extension+\".png\"\n",
        "\n",
        "      # get type according to dataset\n",
        "      image_class = check_class(attributes[1])\n",
        "\n",
        "\n",
        "      move_file_by_class(image_file_name, image_class, img_folder)\n",
        "\n",
        "      count +=1\n",
        "      if count % 100 == 0 and verbose:\n",
        "        print (\"Image Num\"+str(count)+\": \" +image_file_name+ \" is a \" + image_class.name)\n",
        "    print(\"Done moving from \"+img_folder+ \" to data/train/\")\n",
        "\n",
        "\n",
        "\n",
        "  image_folders = [\"png\",\"ima_g\", \"ima_i\", \"ima_u\", \"ima_z\", \"ima_r\"]\n",
        "  extensions =[None, \"g\",\"i\",\"u\",\"z\",\"r\"]\n",
        "\n",
        "  for i in range(0,len(extensions)):\n",
        "    move_files_according_to_txt(txt_filepath = \"data/raw/efigi-1.6/EFIGI_attributes.txt\",\n",
        "                                img_folder = image_folders[i], \n",
        "                                extension = extensions[i], \n",
        "                                verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-A9_M1QcoeW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Shuffle some files from training folder to validation folder\n"
      ]
    },
    {
      "metadata": {
        "id": "nWKfOmBkCbXN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  train_folder = \"./data/train/\"\n",
        "  validation_folder = \"./data/validation/\"\n",
        "\n",
        "  import os, glob, random \n",
        "  subfolders = [f.path for f in os.scandir(train_folder) if f.is_dir()] \n",
        "\n",
        "  # For each training folder \n",
        "  for train_class_dir in subfolders:\n",
        "\n",
        "    # Get total number of files in folder\n",
        "    images = glob.glob(train_class_dir+\"/*.png\")\n",
        "    total_num = len(images)\n",
        "    print (train_class_dir +\" has \" + str(total_num)+\" images.\")\n",
        "\n",
        "    # Shuffle 20% files\n",
        "    number_of_validation = int(0.2*float(total_num)) # 20% validation\n",
        "    files_to_move = random.sample(images, number_of_validation)\n",
        "\n",
        "\n",
        "    class_name = train_class_dir.split(\"/\")[-1]\n",
        "\n",
        "    # Move 20% to the validation folder of the same class\n",
        "    for file_dir in files_to_move:\n",
        "      destination_dir = file_dir.split(\"/train/\")[0]+\"/validation/\"+file_dir.split(\"/train/\")[-1]\n",
        "      shutil.move(file_dir, destination_dir)\n",
        "\n",
        "    num_images_remaining = len(glob.glob(train_class_dir+\"/*.png\"))\n",
        "    print (\"After transfer \" + str(num_images_remaining)+\" images remain.\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lszJVNpPf4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove Raw Files"
      ]
    },
    {
      "metadata": {
        "id": "Ti0g17tmPfcL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  import os, shutil\n",
        "  shutil.rmtree(\"./data/raw\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDIdQ8BQQQGo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Zip and move sorted data to drive"
      ]
    },
    {
      "metadata": {
        "id": "Rw9p0aUSQXmH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if download_raw_data:\n",
        "  ! zip -r sorted_data.zip ./data\n",
        "  ! mv -v sorted_data.zip drive/EFIGI_Galaxy_Classification/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pFLTKb79r4AU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train a deep convolutional neural network calssifier\n",
        "\n",
        "- Galaxy classifier using Inception-ResNet version 2.\n"
      ]
    },
    {
      "metadata": {
        "id": "2pfKo3b02shb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports for ML that will be needed"
      ]
    },
    {
      "metadata": {
        "id": "vJU5Dfq1uYh3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "601bda0d-9f03-498d-b6cd-5dbe923b5b9d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531335146373,
          "user_tz": 240,
          "elapsed": 5147,
          "user": {
            "displayName": "Moad Computer",
            "photoUrl": "//lh5.googleusercontent.com/-Ic6_gWlgQXo/AAAAAAAAAAI/AAAAAAAAABA/KunqdqgBsx4/s50-c-k-no/photo.jpg",
            "userId": "105137350204760020224"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print ('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print ('This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print ('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "    \n",
        "import PIL # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model,                             \\\n",
        "                         model_from_json,                    \\\n",
        "                         load_model\n",
        "from keras.layers import Dense,                             \\\n",
        "                         GlobalAveragePooling2D,            \\\n",
        "                         Dropout,                           \\\n",
        "                         BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,                           \\\n",
        "                             RMSprop,                       \\\n",
        "                             Adagrad\n",
        "from keras.callbacks import EarlyStopping,   \\\n",
        "                            ModelCheckpoint, \\\n",
        "                            ReduceLROnPlateau\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MB6UlsJ0m30a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fetch saved weights from Google drive storage object"
      ]
    },
    {
      "metadata": {
        "id": "ldqlYxjz1nzZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "# Create GoogleDrive instance with authenticated GoogleAuth instance.\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file = drive.CreateFile({'id': '18ZuW3Xb0830YPF0qyCZ5NBZsSESYgW24'})\n",
        "file.GetContentFile('transfer_learn_299_299_.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLAtM8RH16uV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! mv ./*.h5 ./output/checkpoint/transfer_learn_299_299_.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4IvMMYis0kR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9b5cd71-658e-42ad-c76e-9151133c8a5f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531335280444,
          "user_tz": 240,
          "elapsed": 6243,
          "user": {
            "displayName": "Moad Computer",
            "photoUrl": "//lh5.googleusercontent.com/-Ic6_gWlgQXo/AAAAAAAAAAI/AAAAAAAAABA/KunqdqgBsx4/s50-c-k-no/photo.jpg",
            "userId": "105137350204760020224"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print(\n",
        "        'This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "\n",
        "import PIL  # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3, \\\n",
        "    preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, \\\n",
        "    preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model, \\\n",
        "    model_from_json, \\\n",
        "    load_model\n",
        "from keras.layers import Dense, \\\n",
        "    GlobalAveragePooling2D, \\\n",
        "    Dropout, \\\n",
        "    BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, \\\n",
        "    RMSprop, \\\n",
        "    Adagrad\n",
        "from keras.callbacks import EarlyStopping, \\\n",
        "    ModelCheckpoint, \\\n",
        "    ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def generate_timestamp():\n",
        "    \"\"\"\n",
        "    Generates a timestring in the format year_month_day-hr_min_sec\n",
        "\n",
        "    :return: a string that holds the timestring\n",
        "    \"\"\"\n",
        "    timestring = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "    print(\"Time stamp generated: \" + timestring)\n",
        "    return timestring\n",
        "\n",
        "\n",
        "def is_valid_file(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a file passed as an arg exists\n",
        "\n",
        "    :param parser:  an ArgumentParser object that can process command line args\n",
        "    :param arg: filename\n",
        "    :return: the filename if the file exists, otherwise null\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(arg):\n",
        "        parser.error(\"The file %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def is_valid_dir(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a dir passed as an arg exists\n",
        "\n",
        "    :param parser: an ArgumentParser object that can process command line args\n",
        "    :param arg: directory path\n",
        "    :return: the dir path if the dir exists\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(arg):\n",
        "        parser.error(\"The folder %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def string_to_bool(val):\n",
        "    \"\"\"\n",
        "    Converts yes, y, 1, t, n, 0, f, False into their appropriate bools\n",
        "\n",
        "    :param val: a string\n",
        "    :return: the associated bool (True/False) otherwise an error\n",
        "    \"\"\"\n",
        "    if val.lower() in ('yes', 'true', 't', 'y', '1', 'yeah'):\n",
        "        return True\n",
        "    elif val.lower() in ('no', 'false', 'f', 'n', '0', 'none'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected ...')\n",
        "\n",
        "\n",
        "def get_nb_files(directory):\n",
        "    \"\"\"\n",
        "    Gets the number of files in a directory\n",
        "\n",
        "    :param directory: the dir that we are counting the number of files in\n",
        "    :return: the count of the files in the dir (0 if the dir doesnt exist)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    cnt = 0\n",
        "    for r, dirs, files in os.walk(directory):\n",
        "        for dr in dirs:\n",
        "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "    return cnt\n",
        "\n",
        "\n",
        "def setup_to_transfer_learn(model, base_model, optimizer):\n",
        "    \"\"\"\n",
        "    Helps join a previous model (the base model) to new model\n",
        "\n",
        "    ???: where are base_model and model joined\n",
        "\n",
        "    :param model: the new model to be trained\n",
        "    :param base_model: the pre existing base model, already trained\n",
        "    :param optimizer: the optimizer function to train the new model\n",
        "    :return: the new model\n",
        "    \"\"\"\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def add_top_layer(base_model, nb_classes):\n",
        "    \"\"\"\n",
        "    Add a fully connected convolutional neural network layer\n",
        "\n",
        "    ???: confused about x1, x2, x12, x3\n",
        "\n",
        "    :param base_model: the current model\n",
        "    :param nb_classes: the number of classes that we need to predict for\n",
        "    :return: the new model with additional CNN layer\n",
        "    \"\"\"\n",
        "\n",
        "    # create dropout layer\n",
        "    # (drops units from NN to prevent overfitting)\n",
        "    try:\n",
        "        dropout = float(args.dropout[0])\n",
        "    except:\n",
        "        dropout = DEFAULT_DROPOUT\n",
        "        print('Invalid input for dropout ...')\n",
        "\n",
        "    # choose activation function\n",
        "    try:\n",
        "        activation = str(args.activation[0]).lower\n",
        "        print('Building model using default activation function: ' + str(activation))\n",
        "    except:\n",
        "        activation = 'relu'\n",
        "        print('Invalid input for activation function ...')\n",
        "        print(\"Choice of activation functions: hard_sigmoid, elu, linear, relu,\" \n",
        "              \"selu, sigmoid, softmax, softplus, sofsign, tanh ...\")\n",
        "        print('Building model using default activation function: relu')\n",
        "\n",
        "    bm = base_model.output\n",
        "\n",
        "    x = Dropout(dropout)(bm)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(FC_SIZE, activation=activation)(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "\n",
        "    x1 = Dense(FC_SIZE, activation=activation, name=\"fc_dense1\")(x)\n",
        "    x1 = Dropout(dropout, name='dropout1')(x1)\n",
        "    x1 = BatchNormalization(name=\"fc_batch_norm1\")(x1)\n",
        "    x1 = Dense(FC_SIZE, activation=activation, name=\"fc_dense2\")(x1)\n",
        "    x1 = Dropout(dropout, name='dropout2')(x1)\n",
        "\n",
        "    x2 = Dense(FC_SIZE, activation=activation, name=\"fc_dense3\")(x)\n",
        "    x2 = Dropout(dropout, name='dropout3')(x2)\n",
        "    x2 = BatchNormalization(name=\"fc_batch_norm2\")(x2)\n",
        "    x2 = Dense(FC_SIZE, activation=activation, name=\"fc_dense4\")(x2)\n",
        "    x2 = Dropout(dropout, name='dropout4')(x2)\n",
        "\n",
        "    x12 = concatenate([x1, x2], name='mixed11')\n",
        "    x12 = Dropout(dropout, name='dropout5')(x12)\n",
        "    x12 = Dense(FC_SIZE // 16, activation=activation, name='fc_dense5')(x12)\n",
        "    x12 = Dropout(dropout, name='dropout6')(x12)\n",
        "    x12 = BatchNormalization(name=\"fc_batch_norm3\")(x12)\n",
        "    x12 = Dense(FC_SIZE // 32, activation=activation, name='fc_dense6')(x12)\n",
        "    x12 = Dropout(dropout, name='dropout7')(x12)\n",
        "\n",
        "    x3 = GlobalAveragePooling2D(name='global_avg_pooling2')(bm)\n",
        "    x3 = Dense(2048, activation=activation, name='fc_dense7')(x3)\n",
        "    x3 = Dropout(dropout, name='dropout8')(x3)\n",
        "    x3 = BatchNormalization(name=\"fc_batch_norm4\")(x3)\n",
        "    x3 = Dense(2048, activation=activation, name='fc_dense8')(x3)\n",
        "    x3 = Dropout(dropout, name='dropout9')(x3)\n",
        "\n",
        "    xout = concatenate([x12, x3], name='mixed12')\n",
        "    xout = Dense(FC_SIZE // 32, activation=activation, name='fc_dense9')(xout)\n",
        "    xout = Dropout(dropout, name='dropout10')(xout)\n",
        "\n",
        "    predictions = Dense(nb_classes,\n",
        "                        activation='softmax',\n",
        "                        name='prediction')(xout)  # New softmax layer\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS):\n",
        "    \"\"\"\n",
        "    Freezes some of the bottom layers of the model to not be trained\n",
        "\n",
        "    :param model: the current ML model\n",
        "    :param optimizer: optimizer function being used for the training of the model\n",
        "    :param NB_FROZEN_LAYERS: Freeze the bottom NB_LAYERS and retrain the remaining top layers\n",
        "    :return: the updated new model with some of the bottom layers frozen\n",
        "    \"\"\"\n",
        "    for layer in model.layers[:NB_FROZEN_LAYERS]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[NB_FROZEN_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_model(args, name, model):\n",
        "    \"\"\"\n",
        "    Saves the\n",
        "    1) model weights in name.model\n",
        "    2) model config (the number of layers, activation funcs, etc) in name.json.\n",
        "    Both are stored in a dir specified in args.output_dir[0].\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :param name: name of the saved model weights and model config\n",
        "    :param model: the model to be saved\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer_str = file_loc + \"//trained_\" + timestr\n",
        "    file_pointer = os.path.join(file_pointer_str)\n",
        "    model_save_str = file_pointer + \"_weights\" + str(name) + \".model\"\n",
        "    model.save_weights(os.path.join(model_save_str))\n",
        "\n",
        "    model_json = model.to_json()  # Serialize model to JSON\n",
        "    config_save_str = file_pointer + \"_config\" + str(name) + \".json\"\n",
        "    with open(os.path.join(config_save_str), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    print(\"Saved the trained model weights to: \" +\n",
        "          str(os.path.join(file_pointer + \"_weights\" + str(name) + \".model\")))\n",
        "    print(\"Saved the trained model configuration as a json file to: \" +\n",
        "          str(os.path.join(file_pointer + \"_config\" + str(name) + \".json\")))\n",
        "\n",
        "\n",
        "def generate_labels(args):\n",
        "    \"\"\"\n",
        "    Generates labels from folder names in data/train/ and data/validation/\n",
        "    IF the labels from train and validation folders match, labels are returned\n",
        "    and a json with the lables is saved\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :return: a sorted dict with the labels\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer = os.path.join(file_loc + \"//trained_labels\")\n",
        "\n",
        "    data_dir = args.train_dir[0]\n",
        "    val_dir_ = args.val_dir[0]\n",
        "\n",
        "    dt = defaultdict(list)\n",
        "    dv = defaultdict(list)\n",
        "\n",
        "    for root, subdirs, files in os.walk(data_dir):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(data_dir)\n",
        "            suffix = file_path[len(data_dir):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dt[label].append(file_path)\n",
        "\n",
        "    for root, subdirs, files in os.walk(val_dir_):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(val_dir_)\n",
        "            suffix = file_path[len(val_dir_):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dv[label].append(file_path)\n",
        "\n",
        "    labels = sorted(dt.keys())\n",
        "    val_labels = sorted(dv.keys())\n",
        "\n",
        "    if set(labels) == set(val_labels):\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        with open(os.path.join(file_pointer + \".json\"), \"w\") as json_file:\n",
        "            json.dump(labels, json_file)\n",
        "    else:\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        print(\"Mismatched training and validation data labels ...\")\n",
        "        print(\n",
        "            \"Sub-folder names do not match between training and validation \"\n",
        "            \"directories ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def generate_plot(args, name, model_train):\n",
        "    \"\"\"\n",
        "    Checks if plots were made and if so, displays plots of training\n",
        "\n",
        "    :param args: holds the bool about if there were to be plots of\n",
        "    training made, in args.plot[0]\n",
        "    :param name: name of plots\n",
        "    :param model_train: the model that was trained\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    gen_plot = args.plot[0]\n",
        "    if gen_plot == True:\n",
        "        plot_training(args, name, model_train)\n",
        "    else:\n",
        "        print(\"No training summary plots generated ...\")\n",
        "        print(\"Set: --plot True for creating training summary plots\")\n",
        "\n",
        "\n",
        "def plot_training(args, name, history):\n",
        "    \"\"\"\n",
        "    Plots the accuracy vs epoch and loss vs epoch and saves as png files\n",
        "\n",
        "    ???: actual parameter is \"model\" but formal parameter is \"history\"...\n",
        "\n",
        "    :param args: holds the outpt dir\n",
        "    :param name: the names of the plots\n",
        "    :param history: the datapoints of the training\n",
        "    :return: null\n",
        "    \"\"\"\n",
        "    output_loc = args.output_dir[0]\n",
        "\n",
        "    output_file_acc = os.path.join(output_loc +\n",
        "                                   \"//training_plot_acc_\" +\n",
        "                                   timestr + str(name) + \".png\")\n",
        "    output_file_loss = os.path.join(output_loc +\n",
        "                                    \"//training_plot_loss_\" +\n",
        "                                    timestr + str(name) + \".png\")\n",
        "    fig_acc = plt.figure()\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_acc.savefig(output_file_acc, dpi=fig_acc.dpi)\n",
        "    print(\"Successfully created the training accuracy plot: \"\n",
        "          + str(output_file_acc))\n",
        "    plt.close()\n",
        "\n",
        "    fig_loss = plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_loss.savefig(output_file_loss, dpi=fig_loss.dpi)\n",
        "    print(\"Successfully created the loss function plot: \"\n",
        "          + str(output_file_loss))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    \"\"\"\n",
        "    Helper function to train a model based on args\n",
        "\n",
        "    :param args: some of the arguments and possible values are\n",
        "            args.config_file = ['./model/model_efc.json']\n",
        "            args.output_dir = ['./output/']\n",
        "            args.train_dir = ['./data/train/']\n",
        "            args.val_dir = ['./data/validation/']\n",
        "            args.epoch = [10]\n",
        "            args.batch = [4]\n",
        "            args.train_model = [True]\n",
        "            args.load_weights = [False]\n",
        "            args.load_checkpoint = [False]\n",
        "            args.fine_tune = [True]\n",
        "            args.test_aug = [False]\n",
        "            args.train_aug = [False]\n",
        "            args.plot = [False]\n",
        "            args.model_summary = [False]\n",
        "            args.dropout = [0.6]\n",
        "            args.learning_rate = [1e-8]\n",
        "            args.decay = [0.0]\n",
        "            args.optimizer_val = ['rms'] # 'rms', 'sgd', 'ada'\n",
        "            args.frozen_layers = [150]\n",
        "            args.base_model = ['inceptionv4']\n",
        "            args.saved_chkpnt\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "\n",
        "    # Get output dir ##########################################################\n",
        "    if not os.path.exists(args.output_dir[0]):\n",
        "        os.makedirs(args.output_dir[0])\n",
        "\n",
        "    # Get optimizer, learning rate, decay parameters ##########################\n",
        "    optimizer_val = args.optimizer_val[0]\n",
        "    lr = args.learning_rate[0]\n",
        "    decay = args.decay[0]\n",
        "\n",
        "    # Set optimizer based on user input #######################################\n",
        "    if optimizer_val.lower() == 'sgd':\n",
        "        optimizer = SGD(lr=lr, decay=decay, momentum=1, nesterov=True)\n",
        "        print(\"Using SGD as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'rms' or optimizer_val.lower() == 'rmsprop':\n",
        "        optimizer = RMSprop(lr=lr, rho=0.9, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using RMSProp as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'ada':\n",
        "        optimizer = Adagrad(lr=lr, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using Adagrad as the optimizer ...\")\n",
        "    else:\n",
        "        optimizer = DEFAULT_OPTIMIZER\n",
        "\n",
        "    # Get number training samples and classes #################################\n",
        "    nb_train_samples = get_nb_files(args.train_dir[0])\n",
        "    nb_classes = len(glob.glob(args.train_dir[0] + \"/*\"))\n",
        "    print(\"Total number of training samples = \" + str(nb_train_samples))\n",
        "    print(\"Number of training classes = \" + str(nb_classes))\n",
        "\n",
        "    # Get number validation samples and classes ###############################\n",
        "    nb_val_samples = get_nb_files(args.val_dir[0])\n",
        "    nb_val_classes = len(glob.glob(args.val_dir[0] + \"/*\"))\n",
        "    print(\"Total number of validation samples = \" + str(nb_val_samples))\n",
        "    print(\"Number of validation classes = \" + str(nb_val_classes))\n",
        "\n",
        "    # START TRAINING if train labels == valid labels ##########################\n",
        "    if nb_val_classes == nb_classes:\n",
        "        print(\"Initiating training session ...\")\n",
        "    else:\n",
        "        print(\"Mismatched number of training and validation data classes ...\")\n",
        "        print(\"Unequal number of sub-folders found between train and \"\n",
        "              \"validation directories ...\")\n",
        "        print(\"Each sub-folder in train and validation directroies are \"\n",
        "              \"treated as a separate class ...\")\n",
        "        print(\"Correct this mismatch and re-run ...\")\n",
        "        print(\"Now exiting ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Get num epochs, batch size, train aug ###################################\n",
        "    nb_epoch = int(args.epoch[0])\n",
        "    batch_size = int(args.batch[0])\n",
        "    train_aug = args.train_aug[0]\n",
        "\n",
        "    # Grab Base Model to train op top of  [TRANSF LEARNING] ###################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_v4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        preprocess_input = preprocess_input_inceptionv4\n",
        "    else:\n",
        "        preprocess_input = preprocess_input_inceptionv3\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    if train_aug == True:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    test_aug = args.test_aug[0]\n",
        "    if test_aug == True:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Getting training data ###################################################\n",
        "    print(\"Generating training data: ... \")\n",
        "    train_generator = train_datagen.flow_from_directory(args.train_dir[0],\n",
        "                                                        target_size=(\n",
        "                                                        IM_WIDTH, IM_HEIGHT),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "    # Getting validation data #################################################\n",
        "    print(\"Generating validation data: ... \")\n",
        "    validation_generator = test_datagen.flow_from_directory(args.val_dir[0],\n",
        "                                                            target_size=(\n",
        "                                                            IM_WIDTH,\n",
        "                                                            IM_HEIGHT),\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode='categorical')\n",
        "\n",
        "    # If base model an inception net ##########################################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_v4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        base_model = InceptionResNetV2(weights='imagenet', \\\n",
        "                                       include_top=False)\n",
        "        base_model_name = 'Inception version 4'\n",
        "    else:\n",
        "        # Model argument: include_top=False excludes the final FC layer\n",
        "        base_model = InceptionV3(weights='imagenet',\n",
        "                                 include_top=False)\n",
        "        base_model_name = 'Inception version 3'\n",
        "    print('Base model: ' + str(base_model_name))\n",
        "\n",
        "    # Add a new layer to the base model #######################################\n",
        "    model = add_top_layer(base_model, nb_classes)\n",
        "    print(\"New top layer added to: \" + str(base_model_name))\n",
        "\n",
        "    # get classification labels, if to load checkpoints, previous weights,etc #\n",
        "    labels = generate_labels(args)\n",
        "    load_weights_ = args.load_weights[0]\n",
        "    fine_tune_model = args.fine_tune[0]\n",
        "    load_checkpoint = args.load_checkpoint[0]\n",
        "    checkpointer_savepath = os.path.join(args.output_dir[0] +\n",
        "                                         '/checkpoint/Transfer_learn_' +\n",
        "                                         str(IM_WIDTH) + '_' +\n",
        "                                         str(IM_HEIGHT) + '_' + '.h5')\n",
        "\n",
        "    # Getting previous weights from checkpoint, else new model ################\n",
        "    if load_weights_ == True and load_checkpoint == False:\n",
        "        try:\n",
        "            with open(args.config_file[0]) as json_file:\n",
        "                model_json = json_file.read()\n",
        "            model = model_from_json(model_json)\n",
        "        except:\n",
        "            model = model\n",
        "        try:\n",
        "            model.load_weights(args.weights_file[0])\n",
        "            print(\"Loaded model weights from: \" + str(args.weights_file[0]))\n",
        "        except:\n",
        "            print(\"Error loading model weights ...\")\n",
        "            print(\"Loaded default model weights ...\")\n",
        "    elif load_checkpoint == True:\n",
        "        try:\n",
        "            model = load_model(checkpointer_savepath)\n",
        "            print(\n",
        "                \"Loaded model from checkpoint: \" + str(checkpointer_savepath))\n",
        "        except:\n",
        "            if os.path.exists(args.saved_chkpnt[0]):\n",
        "                model = load_model(args.saved_chkpnt[0])\n",
        "                print('Loaded saved checkpoint file ...')\n",
        "            else:\n",
        "                print(\"Error loading model checkpoint ...\")\n",
        "                print(\"Loaded default model weights ...\")\n",
        "    else:\n",
        "        model = model\n",
        "        print(\"Tabula rasa ...\")\n",
        "\n",
        "    # Checking and freezing certain layers during training ####################\n",
        "    try:\n",
        "        NB_FROZEN_LAYERS = args.frozen_layers[0]\n",
        "    except:\n",
        "        NB_FROZEN_LAYERS = DEFAULT_NB_LAYERS_TO_FREEZE\n",
        "    if fine_tune_model == True:\n",
        "        print(\"Fine tuning Inception architecture ...\")\n",
        "        print(\"Frozen layers: \" + str(NB_FROZEN_LAYERS))\n",
        "        setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS)\n",
        "    else:\n",
        "        print(\"Transfer learning using Inception architecture ...\")\n",
        "        setup_to_transfer_learn(model, base_model, optimizer)\n",
        "\n",
        "    # START TRAINING ##########################################################\n",
        "    print(\"Initializing training with  class labels: \" + str(labels))\n",
        "\n",
        "    # checking and printing current model summary prior to training\n",
        "    model_summary_ = args.model_summary[0]\n",
        "    if model_summary_ == True:\n",
        "        print(model.summary())\n",
        "    else:\n",
        "        print(\n",
        "            \"Successfully loaded deep neural network classifier for training \")\n",
        "\n",
        "    # getting checkpoint file prepared\n",
        "    if not os.path.exists(os.path.join(args.output_dir[0] + '/checkpoint/')):\n",
        "        os.makedirs(os.path.join(args.output_dir[0] + '/checkpoint/'))\n",
        "\n",
        "    # setting up checkpoint, learning rate\n",
        "    earlystopper = EarlyStopping(patience=6, verbose=1)\n",
        "    checkpointer = ModelCheckpoint(checkpointer_savepath,\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True)\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                                patience=2,\n",
        "                                                mode='min',\n",
        "                                                epsilon=1e-4,\n",
        "                                                cooldown=1,\n",
        "                                                verbose=1,\n",
        "                                                factor=0.5,\n",
        "                                                min_lr=lr * 1e-2)\n",
        "\n",
        "    # training command\n",
        "    model_train = model.fit_generator(train_generator,\n",
        "                                      epochs=nb_epoch,\n",
        "                                      validation_data=validation_generator,\n",
        "                                      class_weight='auto',\n",
        "                                      callbacks=[earlystopper,\n",
        "                                                 learning_rate_reduction,\n",
        "                                                 checkpointer])\n",
        "\n",
        "    # saving model and training plots\n",
        "    if fine_tune_model == True:\n",
        "        save_model(args, \"_ft_\", model)\n",
        "        generate_plot(args, \"_ft_\", model_train)\n",
        "    else:\n",
        "        save_model(args, \"_tl_\", model)\n",
        "        generate_plot(args, \"_tl_\", model_train)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "########################### DEFAULT PARAMETERS ################################\n",
        "\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299  # Fixed input image size for Inception\n",
        "DEFAULT_EPOCHS = 100\n",
        "DEFAULT_BATCHES = 20\n",
        "FC_SIZE = 4096\n",
        "DEFAULT_DROPOUT = 0.1\n",
        "DEFAULT_NB_LAYERS_TO_FREEZE = 169\n",
        "\n",
        "sgd = SGD(lr=1e-7, decay=0.5, momentum=1, nesterov=True)\n",
        "rms = RMSprop(lr=1e-7, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "ada = Adagrad(lr=1e-3, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "DEFAULT_OPTIMIZER = ada\n",
        "timestr = generate_timestamp()\n",
        "###############################################################################\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time stamp generated: 2018_07_11-18_54_38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "exHK7SQjtqhP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import types\n",
        "\n",
        "model_dir = \"./drive/EFIGI_Galaxy_Classification/model/\"\n",
        "output_dir = \"./drive/EFIGI_Galaxy_Classification/output/\"\n",
        "checkpoint_dir = \"./drive/EFIGI_Galaxy_Classification/output/checkpoint/\"\n",
        "\n",
        "\n",
        "args = types.SimpleNamespace()\n",
        "args.config_file = [model_dir+'model_efc.json']\n",
        "args.output_dir = [output_dir]\n",
        "args.train_dir = ['./data/train/']\n",
        "args.val_dir = ['./data/validation/']\n",
        "args.epoch = [10]\n",
        "args.batch = [4]\n",
        "args.train_model = [True]\n",
        "args.load_weights = [False]\n",
        "args.load_checkpoint = [True] # Set it to true for using a saved checkpoint\n",
        "args.fine_tune = [True]\n",
        "args.test_aug = [False]\n",
        "args.train_aug = [False]\n",
        "args.plot = [True]\n",
        "args.model_summary = [False]\n",
        "args.dropout = [0.6]\n",
        "args.learning_rate = [1e-8]\n",
        "args.decay = [0.0]\n",
        "args.optimizer_val = ['rms'] # 'rms', 'sgd', 'ada'\n",
        "args.frozen_layers = [150]\n",
        "args.base_model = ['inceptionv4']\n",
        "args.saved_chkpnt = [checkpoint_dir+'transfer_learn_299_299_.h5']\n",
        "\n",
        "\n",
        "def ensure_dir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "ensure_dir(model_dir)\n",
        "ensure_dir(output_dir)\n",
        "ensure_dir(checkpoint_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vL_tT3buttew",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "27872b3c-38fc-46b7-a508-385ebea70feb"
      },
      "cell_type": "code",
      "source": [
        "train_model = args.train_model[0]\n",
        "    \n",
        "if train_model ==True:\n",
        "  print (\"Training sesssion initiated ...\")\n",
        "  train(args)\n",
        "else:\n",
        "  print (\"Nothing to do here ...\")\n",
        "  print (\"Try setting the --train_model flag to True ...\")\n",
        "  print (\"For more help, run with -h flag ...\")\n",
        "  sys.exit(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sesssion initiated ...\n",
            "Using RMSProp as the optimizer ...\n",
            "Total number of training samples = 21401\n",
            "Number of training classes = 5\n",
            "Total number of validation samples = 5347\n",
            "Number of validation classes = 5\n",
            "Initiating training session ...\n",
            "Generating training data: ... \n",
            "Found 21401 images belonging to 5 classes.\n",
            "Generating validation data: ... \n",
            "Found 5347 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3FyWbJoGGbqz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "upload = True\n",
        "checkpoint_savepath = './drive/output/checkpoint/'\n",
        "file_name = 'transfer_learn_299_299_.h5'\n",
        "cloud_save(file_name = file_name,\n",
        "           savepath = checkpoint_savepath,\n",
        "           upload = upload,\n",
        "           prefix = 'EFIGI_')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}